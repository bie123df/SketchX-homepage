---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-the-team'></span>

The ultimate vision for **SketchX** is to understand how seeing can be explained by drawing. In other words, how a better understanding of human sketch data can be translated into insights on how human visual systems operate ‚Äî and in turn, how such insights can benefit computer vision and cognitive science at large.

SketchX has been actively investigating all aspects of sketch research since 2012. The problems we study range from conventional tasks such as sketch recognition and sketch synthesis, to those we have pioneered, such as fine-grained sketch-based image retrieval and memory-aware forensic sketch analysis.

<span class='anchor' id='team-members'></span>
## üë•Team Members
<img src="{{ '/images/team_member.png' | relative_url }}" alt="Team Member" style="max-width: 800px; display: block; margin-top: 1em;">


<span class='anchor' id='team-publications'></span>
## üìù Team Publications
1. [**Deeper, Broader and Artier Domain Generalization**](http://openaccess.thecvf.com/content_iccv_2017/html/Li_Deeper_Broader_and_ICCV_2017_paper.html)  
   *Da Li, Yongxin Yang, Yi-Zhe Song, Timothy M. Hospedales*

2. [**Learning to generalize: Meta-learning for domain generalization**](https://ojs.aaai.org/index.php/AAAI/article/view/11596)  
   *Da Li, Yongxin Yang, Yi-Zhe Song, Timothy M Hospedales* 

3. [**Episodic training for domain generalization**](http://openaccess.thecvf.com/content_ICCV_2019/html/Li_Episodic_Training_for_Domain_Generalization_ICCV_2019_paper.html)  
   *Da Li, Jianshu Zhang, Yongxin Yang, Cong Liu, Yi-Zhe Song, Timothy M Hospedales* 

4. [**Fine-grained visual classification via progressive multi-granularity training of jigsaw patches**](https://link.springer.com/chapter/10.1007/978-3-030-58565-5_10)  
   *Ruoyi Du, Dongliang Chang, Ayan Kumar Bhunia, Jiyang Xie, Yi-Zhe Song, Zhanyu Ma, Jun Guo*

5. [**The devil is in the channels: Mutual-channel loss for fine-grained image classification**](https://ieeexplore.ieee.org/abstract/document/9005389/)  
   *Dongliang Chang, Yifeng Ding, Jiyang Xie, Ayan Kumar Bhunia, Xiaoxu Li, Zhanyu Ma, Ming Wu, Jun Guo, Yi-Zhe Song*

6. [**Fine-grained image analysis with deep learning: A survey**](https://ieeexplore.ieee.org/abstract/document/9609630/)  
   *Xiu-Shen Wei, Yi-Zhe Song, Oisin Mac Aodha, Jianxin Wu, Yuxin Peng, Jinhui Tang, Jian Yang, Serge Belongie* 

7. [**Sketch-a-net: A deep neural network that beats humans**](https://link.springer.com/article/10.1007/s11263-016-0932-3)  
   *Qian Yu, Yongxin Yang, Feng Liu, Yi-Zhe Song, Tao Xiang, Timothy M Hospedales* 

8. [**Deep Spatial-Semantic Attention for Fine-Grained Sketch-Based Image Retrieval**](http://openaccess.thecvf.com/content_iccv_2017/html/Song_Deep_Spatial-Semantic_Attention_ICCV_2017_paper.html)  
   *Jifei Song, Yu Qian, Yi-Zhe Song, Tao Xiang, Timothy Hospedales* 

9. [**Generalizable person re-identification by domain-invariant mapping network**](http://openaccess.thecvf.com/content_CVPR_2019/html/Song_Generalizable_Person_Re-Identification_by_Domain-Invariant_Mapping_Network_CVPR_2019_paper.html)  
   *Jifei Song, Yongxin Yang, Yi-Zhe Song, Tao Xiang, Timothy M Hospedales*

10. [**Sketch-a-net that beats humans**](https://arxiv.org/abs/1501.07873)  
   *Qian Yu, Yongxin Yang, Yi-Zhe Song, Tao Xiang, Timothy Hospedales*
    
11. [**Sketch-based image retrieval via siamese convolutional neural network**](https://ieeexplore.ieee.org/abstract/document/7532801/)  
   *Yonggang Qi, Yi-Zhe Song, Honggang Zhang, Jun Liu* 

12. [**Simpler is better: Few-shot semantic segmentation with classifier weight transformer**](http://openaccess.thecvf.com/content/ICCV2021/html/Lu_Simpler_Is_Better_Few-Shot_Semantic_Segmentation_With_Classifier_Weight_Transformer_ICCV_2021_paper.html)  
   *Zhihe Lu, Sen He, Xiatian Zhu, Li Zhang, Yi-Zhe Song, Tao Xiang*

13. [**Sketchmate: Deep hashing for million-scale human sketch retrieval**](http://openaccess.thecvf.com/content_cvpr_2018/html/Xu_SketchMate_Deep_Hashing_CVPR_2018_paper.html)  
   *Peng Xu, Yongye Huang, Tongtong Yuan, Kaiyue Pang, Yi-Zhe Song, Tao Xiang, Timothy M Hospedales, Zhanyu Ma, Jun Guo*

14. [**Doodle to search: Practical zero-shot sketch-based image retrieval**](http://openaccess.thecvf.com/content_CVPR_2019/html/Dey_Doodle_to_Search_Practical_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.html)  
   *Sounak Dey, Pau Riba, Anjan Dutta, Josep Llados, Yi-Zhe Song* 

15. [**Text extraction from natural scene image: A survey**](https://www.sciencedirect.com/science/article/pii/S0925231213006309)  
   *Honggang Zhang, Kaili Zhao, Yi-Zhe Song, Jun Guo*

16. [**Stochastic classifiers for unsupervised domain adaptation**](http://openaccess.thecvf.com/content_CVPR_2020/html/Lu_Stochastic_Classifiers_for_Unsupervised_Domain_Adaptation_CVPR_2020_paper.html)  
   *Zhihe Lu, Yongxin Yang, Xiatian Zhu, Cong Liu, Yi-Zhe Song, Tao Xiang*

17. [**Deep learning for free-hand sketch: A survey**](https://ieeexplore.ieee.org/abstract/document/9706366/)  
   *Peng Xu, Timothy M Hospedales, Qiyue Yin, Yi-Zhe Song, Tao Xiang, Liang Wang*

18. [**Your "Flamingo" is My "Bird": Fine-Grained, or Not**](http://openaccess.thecvf.com/content/CVPR2021/html/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.html)  
   *Dongliang Chang, Kaiyue Pang, Yixiao Zheng, Zhanyu Ma, Yi-Zhe Song, Jun Guo* 

19. [**Style-based global appearance flow for virtual try-on**](http://openaccess.thecvf.com/content/CVPR2022/html/He_Style-Based_Global_Appearance_Flow_for_Virtual_Try-On_CVPR_2022_paper.html)  
   *Sen He, Yi-Zhe Song, Tao Xiang* 

20. [**One loss for all: Deep hashing with a single cosine similarity based learning objective**](https://proceedings.neurips.cc/paper/2021/hash/cbcb58ac2e496207586df2854b17995f-Abstract.html)  
   *Jiun Tian Hoe, Kam Woh Ng, Tianyu Zhang, Chee Seng Chan, Yi-Zhe Song, Tao Xiang*


<span class='anchor' id='honors-and-awards'></span>
## üéñ Honors and Awards
SketchX has established itself as a world-leading research lab on human sketch analytics. We continue to publish sketch-specific papers in top venues and have enjoyed many academic and commercial achievements, including:
- üèÜ *Best Science Paper Award* at **BMVC 2015**
- ü§ù Collaborations with **law enforcement agencies**
- üõçÔ∏è Partnerships with **online retail platforms**
- *27 x CVPR, 11 x ICCV, 11 x ECCV, 2 x SIGGRAPH Asia, 1 x ICLR, 1 x ICML, 1 x NeurIPS (as of July 2022)*

<span class='anchor' id='team-news'></span>
## üî• Team News

<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We are at the stand B3 and B4. See you there! <a href="https://twitter.com/hashtag/AIUK2023?src=hash&amp;ref_src=twsrc%5Etfw">#AIUK2023</a> <a href="https://twitter.com/turinginst?ref_src=twsrc%5Etfw">@turinginst</a> <a href="https://t.co/ElnQumx7xm">https://t.co/ElnQumx7xm</a> <a href="https://t.co/D1MdGWlB1q">pic.twitter.com/D1MdGWlB1q</a></p>&mdash; Surrey Institute for People-Centred AI (@PeopleCentredAI) <a href="https://twitter.com/PeopleCentredAI/status/1638130139027349505?ref_src=twsrc%5Etfw">March 21, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>











